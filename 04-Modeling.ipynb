{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "First let's open our train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "_train_df = pd.read_csv('./train.csv')\n",
    "_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_df.loc[_train_df['status'] == 1, 'status'] = 2\n",
    "_train_df.loc[_train_df['status'] == 0, 'status'] = 1\n",
    "_train_df.loc[_train_df['status'] == 2, 'status'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = _train_df.drop(['status'], axis=1)\n",
    "y_train_df = _train_df['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "params = {'class_weight': [{0: 1, 1: v} for v in range(1, 7)]}\n",
    "# params = [\n",
    "#   {'C': [1, 10, 100, 1000], 'class_weight': [{0: 1, 1: v} for v in range(1, 7)]},\n",
    "# ]\n",
    "# params = {'p': [1, 2], 'weights': ['uniform', 'distance']}\n",
    "# params = {'activation': ['logistic', 'identity', 'relu', 'tanh']}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=LogisticRegression(max_iter=1000000),\n",
    "    # estimator=SVC(probability=True),\n",
    "    param_grid=params,\n",
    "    scoring={'precision': make_scorer(precision_score), 'recall': make_scorer(recall_score), 'auc': make_scorer(roc_auc_score)},\n",
    "    refit='auc',\n",
    "    cv=4,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "grid.fit(x_train_df, y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = grid.best_estimator_\n",
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_train_df, estimator.predict(x_train_df)).ravel()\n",
    "print(f'True positives: {tp}')\n",
    "print(f'True negatives: {tn}')\n",
    "print(f'False positives: {fp}')\n",
    "print(f'False negatives: {fn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_train_df, estimator.predict(x_train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_df = pd.read_csv('./test.csv')\n",
    "_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_df = _test_df.drop(['status'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, mkdir\n",
    "import logging\n",
    "try:\n",
    "    mkdir('log/')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "n = len([f for f in listdir('log/') if f.endswith('csv')])\n",
    "\n",
    "logging.basicConfig(filename='log/submissions.log',\n",
    "                    level=logging.INFO, format='%(message)s')\n",
    "logging.info(f'[submission-{n}.csv] Score of {roc_auc_score(y_train_df, estimator.predict(x_train_df))}')\n",
    "\n",
    "\n",
    "results = {\n",
    "    'Id': x_test_df['loan_id'],\n",
    "    'Predicted': estimator.predict_proba(x_test_df)[:, 1]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(f'log/submission-{n}.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f345244096139f77bad5fb530e51cfcf3c24c5e0e7513cc496e3bc78d413e6ec"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
